{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from statistics import *\n",
    "import heartpy as hp\n",
    "import copy\n",
    "pd.options.display.max_rows = 450\n",
    "\n",
    "patPWV = pd.read_csv(\"PWVbyPatient.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Methods\n",
    "\n",
    "def segmentProcess1(data, sample_rate=240.0):\n",
    "    # Change values ouside possible range to min and max pulse value\n",
    "    data = [0 if i <= 0 else (550 if i > 550 else i) for i in data]\n",
    "    data = hp.filter_signal(data, cutoff=15, sample_rate=sample_rate, order=4, filtertype='lowpass')\n",
    "    data = hp.filter_signal(data, cutoff=.01, sample_rate=sample_rate, order=4, filtertype='highpass')\n",
    "    wd, m = hp.process(hrdata=data, sample_rate=sample_rate, bpmmin=0, bpmmax=550)\n",
    "    return wd, m\n",
    "\n",
    "def segmentProcess2(peakList, sample_rate=240.0):\n",
    "    test = []\n",
    "    # test.append(0)\n",
    "    try:\n",
    "        peakList.insert(0, 0)\n",
    "    except:\n",
    "        peakList = np.insert(peakList, 0, 0)\n",
    "    \n",
    "    for i in range(len(peakList)-2):\n",
    "        a = (peakList[i] + peakList[i+1])/2\n",
    "        b = (peakList[i+1] + peakList[i+2])/2\n",
    "        interval = .15*(b-a)\n",
    "        a += interval\n",
    "        b -= interval\n",
    "        test.append(round(a))\n",
    "        # test.append(round(b))\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/anrath/miniconda3/envs/biopeaks/lib/python3.7/site-packages/numpy/ma/core.py:5240: RuntimeWarning: Mean of empty slice.\n  dtype=dtype, **kwargs)[()]\n/home/anrath/miniconda3/envs/biopeaks/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3703: RuntimeWarning: Degrees of freedom <= 0 for slice\n  **kwargs)\n"
     ]
    }
   ],
   "source": [
    "iter = 20\n",
    "wds = []\n",
    "rngs = []\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for d in range(iter):\n",
    "    if(d+1 < 10):\n",
    "        fileStr = '0' + str(d+1)\n",
    "    else:\n",
    "        fileStr = str(d+1)\n",
    "    data = hp.get_data('Data/Raw Data/Multiple Cath/X0' + fileStr + '.txt', delim = ' ', column_name = 'AO')\n",
    "    wd, _ = segmentProcess1(data)\n",
    "    df1 = pd.DataFrame(wd['hr'])\n",
    "    df = pd.concat([df,df1], axis=1)\n",
    "    wds.append(wd['peaklist'].copy())\n",
    "for i in range(iter):\n",
    "    if(i+1 < 10):\n",
    "        fileStr = '0' + str(i+1)\n",
    "    else:\n",
    "        fileStr = str(i+1)\n",
    "    rngs.append(segmentProcess2(wds[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcStats(wave):\n",
    "    #calculate metrics for each indexed wave saved in individual metric arrays\n",
    "    #remove outliers, save only mean for each metric\n",
    "    #append metric means to new df\n",
    "\n",
    "    #finding maximum, defining region for dic notch\n",
    "    sysMaxi = wave.idxmax()\n",
    "    reg = wave[int(round(sysMaxi*1.05)):int(round(sysMaxi+(len(wave)*.28)))]\n",
    "    diff = reg.diff()\n",
    "\n",
    "    NP = [0,0]\n",
    "\n",
    "\n",
    "    #find dic notch\n",
    "    ser = [0,0]\n",
    "    counter = 0\n",
    "    for index,value in diff.items():\n",
    "        if value < 1:\n",
    "            counter = counter + 1\n",
    "        if value >= 0:\n",
    "            if counter > 0 and counter > ser[1]:\n",
    "                ser[0] = index\n",
    "                ser[1] = counter\n",
    "            counter = 0\n",
    "\n",
    "\n",
    "\n",
    "    #if no dic notch found:\n",
    "    try:\n",
    "        if ser[0] == 0 or ser[1] < len(reg)*.05:\n",
    "            #estimate diastolic pressure as flattest point -> highest diff\n",
    "            #range for diastolic pressure:\n",
    "            diaReg = diff.tail(n=round(len(diff)*.9))\n",
    "            diaP = diaReg.idxmax()\n",
    "            dicN = round(mean([diaReg.idxmax(),diaReg.idxmin()]))\n",
    "            #print(\"NO DIC NOTCH FOUND, estimating...\")\n",
    "        else:\n",
    "            dicN = ser[0]\n",
    "            if round(2*sysMaxi) > dicN+1:\n",
    "                diaP = wave[dicN+1:round(2*sysMaxi)].idxmax()\n",
    "            else:\n",
    "                diaP = dicN+1\n",
    "    except:\n",
    "        return\n",
    "\n",
    "\n",
    "    NP[0] = dicN\n",
    "    NP[1] = diaP\n",
    "\n",
    "    #saving dic notch and diastolic pressure for functions\n",
    "    dicNotch = NP[0]\n",
    "    diaP = NP[1]\n",
    "\n",
    "    #beginning and end of wave\n",
    "    beg = 0\n",
    "    end = wave.last_valid_index()\n",
    "    sysMaxi = wave.idxmax()\n",
    "\n",
    "\n",
    "    #add calculated metrics to lists\n",
    "    pp_pres.append(np.sum(wave))\n",
    "    avg_sys_rise.append(wave[beg:sysMaxi].mean())\n",
    "    sys_rise_area.append(sum(wave[beg:sysMaxi]))\n",
    "    t_sys_rise.append(sysMaxi)\n",
    "    avg_dec.append(wave[sysMaxi:end].mean())\n",
    "    t_dec.append(end - sysMaxi)\n",
    "    dec_area.append(np.sum(wave[sysMaxi:end]))\n",
    "    avg_sys.append(wave[beg:dicNotch].mean())\n",
    "    slope_sys.append((wave[dicNotch] - wave[beg]) / dicNotch)\n",
    "    sys_area.append(sum(wave[beg:dicNotch]))\n",
    "    t_sys.append(dicNotch)\n",
    "    avg_sys_dec.append(wave[sysMaxi:dicNotch].mean())\n",
    "    dn_sys.append(wave[sysMaxi] - wave[dicNotch])\n",
    "    sys_dec_area.append(np.sum(wave[sysMaxi:dicNotch]))\n",
    "    t_sys_dec.append(dicNotch - sysMaxi)\n",
    "    avg_sys_dec_nodia.append(wave[sysMaxi:dicNotch].mean() - wave[diaP])\n",
    "    avg_sys_nodia.append(wave[beg:dicNotch].mean() - wave[diaP])\n",
    "    avg_sys_rise_nodia.append(wave[beg:sysMaxi].mean() - wave[diaP])\n",
    "    avg_dec_nodia.append(wave[sysMaxi:end].mean() - wave[diaP])\n",
    "    slope_dia.append((wave[end] - wave[dicNotch]) / (end - dicNotch))\n",
    "    t_dia.append(end - dicNotch)\n",
    "    avg_dia.append(wave[dicNotch:end].mean())\n",
    "    dn_dia.append(wave[diaP] - wave[dicNotch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = []\n",
    "\n",
    "for j in range(len(wds)):\n",
    "    pp_pres = []\n",
    "    avg_sys_rise = []\n",
    "    sys_rise_area = []\n",
    "    t_sys_rise = []\n",
    "    avg_dec = []\n",
    "    t_dec = []\n",
    "    dec_area = []\n",
    "    avg_sys = []\n",
    "    slope_sys = []\n",
    "    sys_area = []\n",
    "    t_sys = []\n",
    "    avg_sys_dec = []\n",
    "    dn_sys = []\n",
    "    sys_dec_area = []\n",
    "    t_sys_dec = []\n",
    "    avg_sys_dec_nodia = []\n",
    "    avg_sys_nodia = []\n",
    "    avg_sys_rise_nodia = []\n",
    "    avg_dec_nodia = []\n",
    "    slope_dia = []\n",
    "    t_dia = []\n",
    "    avg_dia = []\n",
    "    dn_dia = []\n",
    "\n",
    "    for i in range(len(rngs[j])-1):\n",
    "        # print(\"{a} {b}\".format(a=j, b=i))\n",
    "        lowerB = rngs[j][i]\n",
    "        upperB = rngs[j][i+1]\n",
    "        wave = df.iloc[lowerB:upperB,j].reset_index(drop=True)\n",
    "        calcStats(wave)\n",
    "    metrics.append([pp_pres,avg_sys_rise,sys_rise_area,t_sys_rise,avg_dec,t_dec,dec_area,avg_sys,slope_sys,sys_area,t_sys,avg_sys_dec,dn_sys,sys_dec_area,t_sys_dec,avg_sys_dec_nodia,avg_sys_nodia,avg_sys_rise_nodia,avg_dec_nodia,slope_dia,t_dia,avg_dia,dn_dia,avg_sys_nodia])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the Outliers\n",
    "for pat in range(len(m1)):\n",
    "    for feat in range(len(m1[pat])):\n",
    "        Q1 = np.percentile(m1[pat][feat], 25, interpolation = 'midpoint') \n",
    "        Q3 = np.percentile(m1[pat][feat], 75, interpolation = 'midpoint') \n",
    "        IQR = Q3 - Q1 \n",
    "        \n",
    "        [value for value in m1[pat][feat] if value < (Q3+1.5*IQR) and value > (Q1-1.5*IQR)]"
   ]
  },
  {
   "source": [
    "### Metrics is a list of patients. Each patient list has a list of features. Each list of features has values for each wave calculated.\n",
    "- No outlier math was done."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[21.918096775290028, 7.320903941892177, 8.46308470901489, 5.886691434513426, 28.62240632592815, 11.419684883205445, 7.528060480457145, -9.20217380599224, 23.539330641019735, 3.4609568363302134, 4.363186648136857, -5.631543200661618, 20.294285134952975, 1.1676147553253682, 4.695212081526027, 0.5771139979413021, -10.161681407796197, 16.526089982968045, -5.983495871012943, -9.222296640601012, -24.99628435419805, -8.360229012944043, -6.809776554023589, -4.965500364107032, nan, -17.457002387674933, 9.070285662998433, 5.361254108680158, -7.72426788982375, -6.239394916610785, nan, -7.908052122059977, -7.6172231726880435, -27.711861809384732, -8.010705938133817, 24.57672037914557, -11.769024445611299, 11.148061312446655, nan, -14.26590401520075, -10.220851383173592, -11.487456802860603, -11.052803922385952, -10.825497895721863, -10.719582605942664, -10.760705916712629, -10.475378494513576, -10.372447918270286, -10.146022442174361, -9.989196398165689, -9.583035734750753, -9.383038649998532, -9.334418596283276, -9.23274005255064, -9.20586992965821, -8.981288786029529, -8.821821226896363, -8.679371096665097, -8.623285872482688, -8.692743547867229, 6.857278824788234, 9.89890055042186, 10.720260706600957, 11.787790100364843, 9.043638774879486, 10.751521318704178, 14.257797382177497, 13.586490408721284, 6.914583496081791, 11.171386908451845, 12.994979373893829, 12.189640117940199, 13.82338791462223, 15.062515706219196, 9.130326625448877, 29.559872358267707, -5.258743471039603, 22.39323763410877, 6.260053845282077, 17.312876300592976, 12.603094047642415, 15.480375253893678, 39.18312042743863, 14.470846452289951, 13.625343124449094, 14.977230650645025, 16.728799119270167, 13.77977116237292, nan, 10.250315546053015, 11.576537940741755, 11.46827002737239, 11.232865016386608, 11.640859698942501, 11.625172240435294, 11.396821576134968, 11.666400231197276, 11.469500161890647, 11.556980168529627, 11.300094989468567, 11.264311049892777, 11.092324287378045, 10.823219115927367, nan, 10.468469163176312, 9.976830204548902, 9.582841061828931, 10.437199865611744, nan, nan, 9.40426914027003, 9.138052517139124, nan, nan, nan, 7.900386030729682, 15.168109254804655, 9.51401446344979, 7.875365042654451, 3.9259560667968887, -0.061569721000866225, 13.33742087054627, 4.146298983072832, 3.1810647854760377, 2.044975231070256, -0.38938467185020675, -1.0679001949296736, -2.0355528126304856, -4.173127927744622, -6.268670853948825, -9.063015767773763, -12.019579335201408, -13.399557550625403]\n"
     ]
    }
   ],
   "source": [
    "m1 = metrics\n",
    "p1 = m1[0][1] # pp_pres\n",
    "print(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pat in range(len(m1)):\n",
    "    for feat in range(len(m1[pat])):\n",
    "        Q1 = np.percentile(m1[pat][feat], 25, interpolation = 'midpoint') \n",
    "        Q3 = np.percentile(m1[pat][feat], 75, interpolation = 'midpoint') \n",
    "        IQR = Q3 - Q1 \n",
    "        \n",
    "        # Removing the Outliers\n",
    "        [value for value in m1[pat][feat] if value < (Q3+1.5*IQR) and value > (Q1-1.5*IQR)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(rngs[0])-1):\n",
    "    lowerB = rngs[0][i]\n",
    "    upperB = rngs[0][i+1]\n",
    "\n",
    "    # wave = wds[0]['hr'][lowerB:upperB]\n",
    "    # wave = pd.DataFrame(wave)\n",
    "    # calcStats(wave)\n",
    "    wave = patPWV.iloc[lowerB:upperB,0].reset_index(drop=True)\n",
    "    sysMaxi = wave.idxmax()\n",
    "    reg = wave[int(round(sysMaxi*1.05)):int(round(sysMaxi+(len(wave)*.28)))]\n",
    "    diff = reg.diff()\n",
    "\n",
    "    NP = [0,0]\n",
    "\n",
    "    #find dic notch\n",
    "    ser = [0,0]\n",
    "    counter = 0\n",
    "    for index,value in diff.items():\n",
    "        if value < 1:\n",
    "            counter = counter + 1\n",
    "        if value >= 0:\n",
    "            if counter > 0 and counter > ser[1]:\n",
    "                ser[0] = index\n",
    "                ser[1] = counter\n",
    "            counter = 0\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    #if no dic notch found:\n",
    "    try:\n",
    "        if ser[0] == 0 or ser[1] < len(reg)*.05:\n",
    "            #estimate diastolic pressure as flattest point -> highest diff\n",
    "            #range for diastolic pressure:\n",
    "            diaReg = diff.tail(n=round(len(diff)*.9))\n",
    "            diaP = diaReg.idxmax()\n",
    "            dicN = round(mean([diaReg.idxmax(),diaReg.idxmin()]))\n",
    "            #print(\"NO DIC NOTCH FOUND, estimating...\")\n",
    "        else:\n",
    "            dicN = ser[0]\n",
    "            if round(2*sysMaxi) > dicN+1:\n",
    "                diaP = wave[dicN+1:round(2*sysMaxi)].idxmax()\n",
    "            else:\n",
    "                diaP = dicN+1\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    NP[0] = dicN\n",
    "    NP[1] = diaP\n",
    "\n",
    "\n",
    "    #saving dic notch and diastolic pressure for functions\n",
    "    dicNotch = NP[0]\n",
    "    diaP = NP[1]\n",
    "    \n",
    "    #beginning and end of wave\n",
    "    beg = 0\n",
    "    end = wave.last_valid_index()\n",
    "    sysMaxi = wave.idxmax()\n",
    "    \n",
    "\n",
    "    #add calculated metrics to lists\n",
    "    pp_pres.append(np.sum(wave))\n",
    "    avg_sys_rise.append(wave[beg:sysMaxi].mean())\n",
    "    sys_rise_area.append(sum(wave[beg:sysMaxi]))\n",
    "    t_sys_rise.append(sysMaxi)\n",
    "    avg_dec.append(wave[sysMaxi:end].mean())\n",
    "    t_dec.append(end - sysMaxi)\n",
    "    dec_area.append(np.sum(wave[sysMaxi:end]))\n",
    "    avg_sys.append(wave[beg:dicNotch].mean())\n",
    "    slope_sys.append((wave[dicNotch] - wave[beg]) / dicNotch)\n",
    "    sys_area.append(sum(wave[beg:dicNotch]))\n",
    "    t_sys.append(dicNotch)\n",
    "    avg_sys_dec.append(wave[sysMaxi:dicNotch].mean())\n",
    "    dn_sys.append(wave[sysMaxi] - wave[dicNotch])\n",
    "    sys_dec_area.append(np.sum(wave[sysMaxi:dicNotch]))\n",
    "    t_sys_dec.append(dicNotch - sysMaxi)\n",
    "    avg_sys_dec_nodia.append(avg_sys_dec[i] - wave[diaP])\n",
    "    avg_sys_nodia.append(avg_sys[i] - wave[diaP])\n",
    "    avg_sys_rise_nodia.append(avg_sys_rise[i] - wave[diaP])\n",
    "    avg_dec_nodia.append(avg_dec[i] - wave[diaP])\n",
    "    slope_dia.append((wave[end] - wave[dicNotch]) / (end - dicNotch))\n",
    "    t_dia.append(end - dicNotch)\n",
    "    avg_dia.append(wave[dicNotch:end].mean())\n",
    "    dn_dia.append(wave[diaP] - wave[dicNotch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove outliers and calculate mean per metic in each list    \n",
    "    \n",
    "pp_pres = pd.Series(pp_pres)\n",
    "pp_pres = pp_pres[pp_pres.between(pp_pres.quantile(.15), pp_pres.quantile(.85))]\n",
    "pp_pres = mean(pp_pres)\n",
    "\n",
    "avg_sys_rise = pd.Series(avg_sys_rise)\n",
    "avg_sys_rise = avg_sys_rise[avg_sys_rise.between(avg_sys_rise.quantile(.15), avg_sys_rise.quantile(.85))]\n",
    "avg_sys_rise = mean(avg_sys_rise)\n",
    "\n",
    "sys_rise_area = pd.Series(sys_rise_area)\n",
    "sys_rise_area = sys_rise_area[sys_rise_area.between(sys_rise_area.quantile(.15), sys_rise_area.quantile(.85))]\n",
    "sys_rise_area = mean(sys_rise_area)\n",
    "\n",
    "t_sys_rise = pd.Series(t_sys_rise)\n",
    "t_sys_rise = t_sys_rise[t_sys_rise.between(t_sys_rise.quantile(.15), t_sys_rise.quantile(.85))]\n",
    "t_sys_rise = mean(t_sys_rise)\n",
    "\n",
    "avg_dec = pd.Series(avg_dec)\n",
    "avg_dec = avg_dec[avg_dec.between(avg_dec.quantile(.15), avg_dec.quantile(.85))]\n",
    "avg_dec = mean(avg_dec)\n",
    "\n",
    "t_dec = pd.Series(t_dec)\n",
    "t_dec = t_dec[t_dec.between(t_dec.quantile(.15), t_dec.quantile(.85))]\n",
    "t_dec = mean(t_dec)\n",
    "\n",
    "dec_area = pd.Series(dec_area)\n",
    "dec_area = dec_area[dec_area.between(dec_area.quantile(.15), dec_area.quantile(.85))]\n",
    "dec_area = mean(dec_area)\n",
    "\n",
    "avg_sys = pd.Series(avg_sys)\n",
    "avg_sys = avg_sys[avg_sys.between(avg_sys.quantile(.15), avg_sys.quantile(.85))]\n",
    "avg_sys = mean(avg_sys)\n",
    "\n",
    "slope_sys = pd.Series(slope_sys)\n",
    "slope_sys = slope_sys[slope_sys.between(slope_sys.quantile(.15), slope_sys.quantile(.85))]\n",
    "slope_sys = mean(slope_sys)\n",
    "\n",
    "sys_area = pd.Series(sys_area)\n",
    "sys_area = sys_area[sys_area.between(sys_area.quantile(.15), sys_area.quantile(.85))]\n",
    "sys_area = mean(sys_area)\n",
    "\n",
    "t_sys = pd.Series(t_sys)\n",
    "t_sys = t_sys[t_sys.between(t_sys.quantile(.15), t_sys.quantile(.85))]\n",
    "t_sys = mean(t_sys)\n",
    "\n",
    "avg_sys_dec = pd.Series(avg_sys_dec)\n",
    "avg_sys_dec = avg_sys_dec[avg_sys_dec.between(avg_sys_dec.quantile(.15), avg_sys_dec.quantile(.85))]\n",
    "avg_sys_dec = mean(avg_sys_dec)\n",
    "\n",
    "dn_sys = pd.Series(dn_sys)\n",
    "dn_sys = dn_sys[dn_sys.between(dn_sys.quantile(.15), dn_sys.quantile(.85))]\n",
    "dn_sys = mean(dn_sys)\n",
    "\n",
    "sys_dec_area = pd.Series(sys_dec_area)\n",
    "sys_dec_area = sys_dec_area[sys_dec_area.between(sys_dec_area.quantile(.15), sys_dec_area.quantile(.85))]\n",
    "sys_dec_area = mean(sys_dec_area)\n",
    "\n",
    "t_sys_dec = pd.Series(t_sys_dec)\n",
    "t_sys_dec = t_sys_dec[t_sys_dec.between(t_sys_dec.quantile(.15), t_sys_dec.quantile(.85))]\n",
    "t_sys_dec = mean(t_sys_dec)\n",
    "\n",
    "avg_sys_dec_nodia = pd.Series(avg_sys_dec_nodia)\n",
    "avg_sys_dec_nodia = avg_sys_dec_nodia[avg_sys_dec_nodia.between(avg_sys_dec_nodia.quantile(.15), avg_sys_dec_nodia.quantile(.85))]\n",
    "avg_sys_dec_nodia = mean(avg_sys_dec_nodia)\n",
    "\n",
    "avg_sys_nodia = pd.Series(avg_sys_nodia)\n",
    "avg_sys_nodia = avg_sys_nodia[avg_sys_nodia.between(avg_sys_nodia.quantile(.15), avg_sys_nodia.quantile(.85))]\n",
    "avg_sys_nodia = mean(avg_sys_nodia)\n",
    "\n",
    "avg_sys_rise_nodia = pd.Series(avg_sys_rise_nodia)\n",
    "avg_sys_rise_nodia = avg_sys_rise_nodia[avg_sys_rise_nodia.between(avg_sys_rise_nodia.quantile(.15), avg_sys_rise_nodia.quantile(.85))]\n",
    "avg_sys_rise_nodia = mean(avg_sys_rise_nodia)\n",
    "\n",
    "avg_dec_nodia = pd.Series(avg_dec_nodia)\n",
    "avg_dec_nodia = avg_dec_nodia[avg_dec_nodia.between(avg_dec_nodia.quantile(.15), avg_dec_nodia.quantile(.85))]\n",
    "avg_dec_nodia = mean(avg_dec_nodia)\n",
    "             \n",
    "slope_dia = pd.Series(slope_dia)\n",
    "slope_dia = slope_dia[slope_dia.between(slope_dia.quantile(.15), slope_dia.quantile(.85))]\n",
    "slope_dia = mean(slope_dia)\n",
    "\n",
    "t_dia = pd.Series(t_dia)\n",
    "t_dia = t_dia[t_dia.between(t_dia.quantile(.15), t_dia.quantile(.85))]\n",
    "t_dia = mean(t_dia)\n",
    "\n",
    "avg_dia = pd.Series(avg_dia)\n",
    "avg_dia = avg_dia[avg_dia.between(avg_dia.quantile(.15), avg_dia.quantile(.85))]\n",
    "avg_dia = mean(avg_dia)\n",
    "\n",
    "dn_dia = pd.Series(dn_dia)\n",
    "dn_dia = dn_dia[dn_dia.between(dn_dia.quantile(.15), dn_dia.quantile(.85))]\n",
    "dn_dia = mean(dn_dia)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3710jvsc74a57bd02f7f656c95ef25adda2ffb3aa867deadb314eb282914ad1b63eb9089e0161731",
   "display_name": "Python 3.7.10 64-bit ('biopeaks': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}